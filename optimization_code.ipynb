{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Mini-Batch Gradient Descent\n",
    "\n",
    "First I would like to introduce a little the types of Mini-batch sizes. Broadly speaking, the Gradient Descent algorithm is used to find the optimal values ​​of a model's parameters (such as the weights of a neural network) that minimize a cost or loss function. There are three main variants of Gradient Descent:\n",
    "\n",
    "* **Batch Gradient Descend**: would be the 'default' where calculates the gradient of the cost function using the entire training data set (mini-batch size = m). Accurate, but slow in learning time and needs resources.\n",
    "\n",
    "* **Stochastic Gradient Descent (SGD)**: when the mini-batch size is 1, calculates the gradient using only one training example at a time. Although it is much faster, it can be noisy and does not always converge stably.\n",
    "\n",
    "And finally the one used:\n",
    "* **Mini-Batch Gradient Descent**: It is a combination of the previous two. Instead of using the entire data set or a single example, the algorithm uses small subsets of data called mini-batches. The size of the mini-batch is an *hyperparameter*.\n",
    "\n",
    "Therefore, we take our traning set and create subsets of the training examples with a *mini-batch size*, then we will update the parameters for each subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Mini-Batch Gradient Descent  (optimization 1)\"\"\"  \n",
    "import math\n",
    "\n",
    "\"\"\"\n",
    "    X --> (n_x,m)   : n_x pixels (features)\n",
    "    Y --> (n_y,m)   : n_y output_clases\n",
    "\"\"\"\n",
    "def random_mini_batches(X, Y, mini_batch_size=32):\n",
    "\n",
    "    # Retrieves the number of total images (training examples)\n",
    "    m = X.shape[1]\n",
    "    mini_batches = []\n",
    "\n",
    "    #Step 1: We create the suffled version for training\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation]\n",
    "\n",
    "    #Step 2: From shuffled version, we create the minibatches\n",
    "    inc = mini_batch_size\n",
    "    num_complete_minibatch = math.floor(m / mini_batch_size)        # Max number of complete batches possible\n",
    "\n",
    "    for k in range(0,num_complete_minibatch):\n",
    "\n",
    "        # For each mini-batch k, slices a subset\n",
    "        mini_batch_X = shuffled_X[:, k*inc : (k+1)*inc]\n",
    "        mini_batch_Y = shuffled_Y[:, k*inc : (k+1)*inc]\n",
    "\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "\n",
    "    if m % mini_batch_size != 0:\n",
    "        \n",
    "        #If not perfectly divisible, last mini-batch with the remaining\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatch*inc : ]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatch*inc : ]\n",
    "\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "\n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Momentum with Gradient Descent\n",
    "\n",
    "Momentum is an optimization technique that is used together with the Gradient Descent algorithm to accelerate convergence and overcome problems such as oscillations in the direction of descent. \n",
    "* The idea is that instead of simply updating the model parameters using the gradient of the cost function at each step, Momentum adds a fraction of the previous update to the new update. This helps smooth the path to the minimum.\n",
    "\n",
    "Momentum Formula:  \n",
    "$$\n",
    "   v_t = \\gamma v_{t-1} + \\eta \\nabla J(\\theta_t)\n",
    "$$\n",
    "\n",
    "   Where:\n",
    "   - \\(v_t\\) at time 𝑡. It represents the exponentially moving average of the gradients up to time 𝑡.\n",
    "   - $\\gamma$ Momentum coefficient (often denoted as **beta_1** in the context of the Adam optimizer). It controls the contribution of past gradients to the current update.\n",
    "   - $\\eta$ learning rate, an *hyperparameter*.\n",
    "   - \\($\\nabla$ J($\\theta_t$\\)  gradient of the cost function with respect to the parameters at time \\(t\\).\n",
    "\n",
    "\n",
    "Now there's another hyperparameter Momentum coefficient  $\\eta$, **usually a value of 0.9 or close to it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Momentum for Gradient Descent (optimization 2)\"\"\"\n",
    "# When using minibatches for update we make the update just with a subset of examples. \n",
    "# Momentum takes in account past gradients to smooth the update.\n",
    "\n",
    "#Step 1 - Intialize velocity 'v' to zeros (same shape as parameters matrix)\n",
    "def initilize_velocity(parameters):\n",
    "    \n",
    "    L = len(parameters) // 2\n",
    "\n",
    "    v = {}\n",
    "\n",
    "    for l in range(1,L+1):\n",
    "\n",
    "        v[\"dW\"+str(l)] = np.zeros((parameters[\"W\"+str(l)].shape))\n",
    "        v[\"db\"+str(l)] = np.zeros((parameters[\"b\"+str(l)].shape))\n",
    "\n",
    "    return v\n",
    "\n",
    "#Step 2 - Update parameters with momentum\n",
    "def update_parameters_with_momentum(parameters, grads, v, beta, learning_rate):\n",
    "\n",
    "    L = len(parameters) // 2\n",
    "\n",
    "    for l in range(1,L+1):\n",
    "\n",
    "        #Exponentially Weighted Averages (Formula above)\n",
    "        v[\"dW\"+str(l)] = beta * v[\"dW\"+str(l)] + (1-beta) * grads[\"dW\"+str(l)]\n",
    "        v[\"db\"+str(l)] = beta * v[\"db\"+str(l)] + (1-beta) * grads[\"db\"+str(l)]\n",
    "\n",
    "        #Update of parameters with momentum\n",
    "        parameters[\"W\"+str(l)] = parameters[\"W\"+str(l)] - learning_rate * v[\"dW\"+str(l)]\n",
    "        parameters[\"b\"+str(l)] = parameters[\"b\"+str(l)] - learning_rate * v[\"db\"+str(l)]\n",
    "\n",
    "    return parameters, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Adam Algorithm --> Momentum + RMSProp\n",
    "\n",
    "The Adam (Adaptive Moment Estimation) optimization technique is one of the most popular and effective algorithms in the field of deep learning. It combines ideas from two optimization techniques: Momentum and RMSprop. Adam adapts the learning rate of each parameter and makes adjustments based on estimates of the first and second moments of the gradient.\n",
    "\n",
    "* How does Adam Works?\n",
    "\n",
    "    - First, it calculates an exponentially weighted average of past gradient, and stores it variables before bias correction and after bias correction. (Similar such as *Momentum*)\n",
    "\n",
    "    - Secondly, it calculates an exponentially weighted average of the squares of the past gradients, and stores it before and after bias correction. (Similar such as *RMSProp*)\n",
    "    *RMSPROP  maintains a moving average of the squares of the gradients*\n",
    "\n",
    "    - Finally, it updates the parameters in a direction based on a combining information of the First and Second steps.\n",
    "\n",
    "* Steps:\n",
    "### 1. Parameter Initialization\n",
    "- ( t = 0 )     -->     (iteration/epoch counter).\n",
    "- ( m_0 = 0 )   -->     (first moment: average of the gradients).\n",
    "- ( v_0 = 0 )   -->     (second moment: mean of the squares of the gradients).\n",
    "- ( $beta_1$ and $beta_2$ ) --> (exponential decay coefficients for the first and second moments, respectively).\n",
    "- ( $alpha$ )   -->     (learning rate).\n",
    "- ( $epsilon$ ) -->     (numerical stability term, typically ( $10^{-8}$ )).\n",
    "\n",
    "### 2. Updating the Counter\n",
    "Increase the iteration counter: $t = t + 1$\n",
    "\n",
    "### 3. Gradient Calculation\n",
    "Calculate the cost gradient with respect to the parameters \\($\\theta$\\). In step (t):     $ g_t = \\nabla_{\\theta} J(\\theta_t)$\n",
    "\n",
    "where \\( J($\\theta_t$) \\) its the cost function.\n",
    "\n",
    "### 4. First Moment Calculation (Gradient Average)\n",
    "Update the first moment (average of the gradients):\n",
    "$$\n",
    "m_t = \\beta_1 \\cdot m_{t-1} + (1 - \\beta_1) \\cdot g_t\n",
    "$$\n",
    "\n",
    "### 5. Calculation of the Second Moment (Average of the Squares of the Gradients)\n",
    "Update the second moment (mean of the squares of the gradients):\n",
    "$$\n",
    "v_t = \\beta_2 \\cdot v_{t-1} + (1 - \\beta_2) \\cdot g_t^2\n",
    "$$\n",
    "\n",
    "### 6. Bias Correction\n",
    "Correct the bias of the first moment:\n",
    "$$\n",
    "\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}\n",
    "$$\n",
    "Correct the bias of the second moment:\n",
    "$$\n",
    "\\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}\n",
    "$$\n",
    "\n",
    "### 7. Update Parameters\n",
    "Update parameters \\( $\\theta$ \\):\n",
    "$$\n",
    "\\theta_t = \\theta_{t-1} - \\alpha \\cdot \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}\n",
    "$$\n",
    "\n",
    "This process repeats until the model converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Adam Algorithm = Momentum + RMSProp (optimization 3)\"\"\"\n",
    "#Step 1: Initialize with Adam:\n",
    "# \n",
    "# matrix to zeros and same shape as parameters\n",
    "#  \n",
    "# v --> exponentially weighted average. \n",
    "# s --> exponentially weighted average of the squares.\n",
    "def initialize_parameters_adam(parameters):\n",
    "\n",
    "    L = len(parameters) // 2\n",
    "\n",
    "    v = {}\n",
    "    s = {}\n",
    "\n",
    "    for l in range(1,L+1):\n",
    "\n",
    "        v[\"dW\" + str(l)] = np.zeros((parameters[\"W\"+str(l)].shape))\n",
    "        v[\"db\" + str(l)] = np.zeros((parameters[\"b\"+str(l)].shape))\n",
    "        s[\"dW\" + str(l)] = np.zeros((parameters[\"W\"+str(l)].shape))\n",
    "        s[\"db\" + str(l)] = np.zeros((parameters[\"b\"+str(l)].shape))\n",
    "        \n",
    "    return v, s\n",
    "\n",
    "#Step 2: Calculates the respective exponentially weighted average of past gradient before and after bias correction and updates the parameters\n",
    "\n",
    "def update_parameters_with_adam(parameters, grads, v, s, t, beta1, beta2, learning_rate, epsilon):\n",
    "    \n",
    "    L = len(parameters) // 2\n",
    "\n",
    "    v_corrected = {}\n",
    "    s_corrected = {}\n",
    "\n",
    "    for l in range(1, L+1):\n",
    "\n",
    "        # exponential weighted average 'v' --> formula (4)\n",
    "        v[\"dW\" + str(l)] = beta1 * v[\"dW\" + str(l)] + (1-beta1) * grads[\"dW\"+str(l)]\n",
    "        v[\"db\" + str(l)] = beta1 * v[\"db\" + str(l)] + (1-beta1) * grads[\"db\"+str(l)]\n",
    "\n",
    "        # bias correction 'v' --> formula (6.1)\n",
    "        v_corrected[\"dW\"+str(l)] = v[\"dW\"+str(l)] / (1-np.power(beta1,t))\n",
    "        v_corrected[\"db\"+str(l)] = v[\"db\"+str(l)] / (1-np.power(beta1,t))\n",
    "\n",
    "        # exponentially weighted average of the squares 's'. --> formula (5)\n",
    "        s[\"dW\"+str(l)] = beta2 * s[\"dW\"+str(l)] + (1 - beta2) * np.power(grads[\"dW\"+str(l)], 2)\n",
    "        s[\"db\"+str(l)] = beta2 * s[\"db\"+str(l)] + (1 - beta2) * np.power(grads[\"db\"+str(l)], 2)\n",
    "        \n",
    "        # bias correction 's' --> formula (6.2)\n",
    "        s_corrected[\"dW\" + str(l)] = s[\"dW\"+str(l)] / (1-np.power(beta2,t))\n",
    "        s_corrected[\"db\" + str(l)] = s[\"db\"+str(l)] / (1-np.power(beta2,t))\n",
    "\n",
    "        # update parameters --> formula (7)\n",
    "        parameters[\"W\"+str(l)] = parameters[\"W\"+str(l)] - learning_rate * (v_corrected[\"dW\"+str(l)] / (np.sqrt(s_corrected[\"dW\"+str(l)]) + epsilon))\n",
    "        parameters[\"b\"+str(l)] = parameters[\"b\"+str(l)] - learning_rate * (v_corrected[\"db\"+str(l)] / (np.sqrt(s_corrected[\"db\"+str(l)]) + epsilon))\n",
    "\n",
    "    return parameters, v, s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Regularization to reduce Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 - L2 Regularization\n",
    "\n",
    "L2 regularization is a technique used to prevent overfitting in models and its goal is to improve the generalization of the model by penalizing large values ​​of model parameters. \n",
    "\n",
    "This helps keep the model weights smaller and therefore prevents the model from overfitting the training data.\n",
    "\n",
    "* The idea is to add a penalty to the term of the model loss function based on the magnitude of the model weights. Mathematically, this is achieved by adding a penalty function to the original loss function.\n",
    "\n",
    "Function: \n",
    "$$\n",
    "J_{\\text{regularized}}(\\theta) = J(\\theta) + \\frac{\\lambda}{2} \\sum_{i=1}^{n} \\theta_i^2\n",
    "$$\n",
    "\n",
    "Now, λ is the regularization parameter (also known as regularization coefficient). Control the strength of the penalty. A value of larger λ means a stronger penalty.\n",
    "\n",
    "The $\\sum_{i=1}^{n} \\theta_i^2$ is the sum of the squares of all model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Regularization -- Reduce Overfitting --> L2\"\"\"\n",
    "\n",
    "#Step 1: compute the cost\n",
    "def compute_cost_with_regularization(AL, Y, parameters, lambd):\n",
    "\n",
    "    m = Y.shape[1]\n",
    "\n",
    "    cross_entropy_cost = bce_compute(AL,Y)\n",
    "\n",
    "    L2_regularization_cost = 0\n",
    "\n",
    "    for key in parameters:\n",
    "        if 'W' in key:\n",
    "            L2_regularization_cost += np.sum(np.square(parameters[key]))\n",
    "\n",
    "\n",
    "    # we add this formula of above\n",
    "    L2_regularization_cost = (lambd / (2 * m)) * L2_regularization_cost\n",
    "\n",
    "    cost = cross_entropy_cost + L2_regularization_cost\n",
    "\n",
    "    return  cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 - Dropout\n",
    "\n",
    "Dropout involves randomly deactivating a fraction of the neurons during training of the neural network. This means that, in each training iteration, certain neurons and their connections are temporarily \"removed\", and do not contribute to the activation or gradient calculation in that iteration.\n",
    "\n",
    "Visual example: \n",
    "<center>\n",
    "<video width=\"400\" height=\"260\" src=\"explanations_utils/dropout1_kiank.mp4\" type=\"video/mp4\" controls>\n",
    "</video>\n",
    "</center>\n",
    "\n",
    "*Finally, if we are **predicting** we **dont use the dropout***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paso 3: Forward propagation model with dropout\n",
    "#\n",
    "# Now we recieve the dropout probabiliy (a new hyperparameter)\n",
    "# And layers drop, indicates which layers apply dropout (1 or 0), 1 will be aplied\n",
    "\n",
    "def L_model_forward(X, parameters, dropout_prob=0, layers_drop=[0, 0, 0, 0, 0]):\n",
    "\n",
    "    caches = []\n",
    "\n",
    "    L = len(parameters) // 2\n",
    "    A = X\n",
    "\n",
    "    keep_prob = 1 - dropout_prob    # probability of keeping neurons active (1 - dropout_prob)\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        \n",
    "        A_prev = A\n",
    "\n",
    "        A, cache = linear_activation_forward(A_prev, parameters[\"W\"+str(l)], parameters[\"b\"+str(l)], \"relu\")\n",
    "\n",
    "        \n",
    "        D = np.random.rand(*A.shape)            # 1. Generate a dropout mask  \n",
    "        D = (D < keep_prob).astype(int)         # 2. Convert to binary mask based on the keep_prob\n",
    "        A = A * D                               # 3. Apply dropout (in which is zero (some neurons))\n",
    "        A = A/keep_prob                         # Scale activation to maintain expectation         \n",
    "            \n",
    "        cache = (cache , D)                     # 4. Caches the dropout mask for use in backpropagation\n",
    "\n",
    "        caches.append(cache)       \n",
    "\n",
    "\n",
    "    #Treat the last layer, sigmoid:\n",
    "    AL, cache = linear_activation_forward(A, parameters[\"W\"+str(L)], parameters[\"b\"+str(L)], \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "\n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches, dropout_prob=0, layers_drop=[0, 0, 0, 0, 0]):\n",
    "    grads = {}\n",
    "    L = len(caches)\n",
    "    \n",
    "    \n",
    "    m = Y.shape[1]\n",
    "    AL = AL.reshape(Y.shape)\n",
    "\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "\n",
    "    current_cache = caches[L - 1]\n",
    "    linear_cache, activation_cache = current_cache\n",
    "    grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_backward(dAL, linear_cache, \"sigmoid\")\n",
    "\n",
    "    for l in reversed(range(L - 1)):\n",
    "        current_cache = caches[l]\n",
    "        linear_cache, activation_cache = current_cache\n",
    "\n",
    "        if layers_drop[l]:                                  # 1. If that was layer dropout was activated\n",
    "            D = activation_cache[1]                         # 2. Dropout mask\n",
    "            dA = grads[\"dA\" + str(l + 2)]\n",
    "            dA = dA * D                                     # 3. Apply mask\n",
    "            dA = dA / (1 - dropout_prob)                    # 4. Scale again as we did in forward.\n",
    "            grads[\"dA\" + str(l + 2)] = dA\n",
    "\n",
    "        grads[\"dA\" + str(l + 1)], grads[\"dW\" + str(l + 1)], grads[\"db\" + str(l + 1)] = linear_backward(grads[\"dA\" + str(l + 2)], linear_cache, \"relu\")\n",
    "\n",
    "    return grads"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
